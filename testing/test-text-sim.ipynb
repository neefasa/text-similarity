{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is for testing out different approaches to comparing two different samples of text and measuring how similar they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1 = \"The easiest way to earn points with Fetch Rewards is to just shop for the products you already love. If you have any participating brands on your receipt, you'll get points based on the cost of the products. You don't need to clip any coupons or scan individual barcodes. Just scan each grocery receipt after you shop and we'll find the savings for you.\"\n",
    "sample2 = \"The easiest way to earn points with Fetch Rewards is to just shop for the items you already buy. If you have any eligible brands on your receipt, you will get points based on the total cost of the products. You do not need to cut out any coupons or scan individual UPCs. Just scan your receipt after you check out and we will find the savings for you.\"\n",
    "sample3 = \"We are always looking for opportunities for you to earn more points, which is why we also give you a selection of Special Offers. These Special Offers are opportunities to earn bonus points on top of the regular points you earn every time you purchase a participating brand. No need to pre-select these offers, we'll give you the points whether or not you knew about the offer. We just think it is easier that way.\"\n",
    "\n",
    "samples = {\n",
    "    'Sample1' : sample1,\n",
    "    'Sample2' : sample2,\n",
    "    'Sample3' : sample3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample1 has 64 words\n",
      "Sample2 has 69 words\n",
      "Sample3 has 75 words\n"
     ]
    }
   ],
   "source": [
    "for sample_num, text in samples.items():\n",
    "    print(f'{sample_num} has {len(text.split())} words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### First approach - Word Count and Cosine Similarity\n",
    "For this first approach I tackled it by doing a word count for each text sample and then measured the similarity using cosine similarity. \n",
    "* Clean text\n",
    "* Set up arrays that will count the occurences of words in each sample\n",
    "* Calulate the cosine similarity between the resulting arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_clean(text:str):\n",
    "    '''Simple function to remove [,.] and to make all letters lowercase.'''\n",
    "    return text.lower().replace(',','').replace('.','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(vector1, vector2):\n",
    "    '''\n",
    "    Recreate the cosine similarity function. \n",
    "    Takes two vectors and outputs a float between 0 and 1.\n",
    "    Closer to 1 means they are more similar.\n",
    "    Closer to 0 means they are less similar.\n",
    "    '''\n",
    "    return np.dot(vector1, vector2) / (np.linalg.norm(vector1) * np.linalg.norm(vector2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(text1:str, text2:str):\n",
    "    '''\n",
    "    Takes two strings and returns two vectors of their word counts.\n",
    "    '''\n",
    "    word_list = []\n",
    "    t1_word_count = []\n",
    "    \n",
    "    #Vectorize text1\n",
    "    for word in simple_clean(text1).split():\n",
    "        if word in word_list:\n",
    "            t1_word_count[word_list.index(word)] += 1\n",
    "        else:\n",
    "            word_list.append(word)\n",
    "            t1_word_count.append(1)\n",
    "    \n",
    "    #Create list of zeros for text2\n",
    "    t2_word_count = [0 for _ in t1_word_count]\n",
    "    \n",
    "    #Vectorize text2\n",
    "    for word in simple_clean(text2).split():\n",
    "        if word in word_list:\n",
    "            t2_word_count[word_list.index(word)] += 1\n",
    "        else:\n",
    "            word_list.append(word)\n",
    "            t1_word_count.append(0)\n",
    "            t2_word_count.append(1)\n",
    "            \n",
    "    return word_list, t1_word_count, t2_word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_similarity(samples):\n",
    "    for (name1,text1),(name2,text2) in combinations(samples.items(), 2):\n",
    "        vector1, vector2 = vectorize_text(text1, text2)[1:]\n",
    "        similarity_score = cos_sim(vector1, vector2)\n",
    "        print(f'{name1} and {name2} have a similarity of {similarity_score:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample1 and Sample2 have a similarity of 0.89\n",
      "Sample1 and Sample3 have a similarity of 0.56\n",
      "Sample2 and Sample3 have a similarity of 0.58\n"
     ]
    }
   ],
   "source": [
    "measure_similarity(samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
